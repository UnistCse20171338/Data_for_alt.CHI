Appendix F: 또 다른 오류
이 섹션은 본 자가민족지학 연구 과정에서 경험한 AI 정보의 한계와 그로 인한 연구자의 정서적 혼란, 그리고 신뢰 재구축의 과정을 기록한다. 이는 AI와의 상호작용을 통한 '감정 → AI의 응답 → 해석 (E→R→I)' 프레임워크의 작동 양상 및 본 논문의 주요 자가민족지학적 분석 기간이 완료된 이후 발생한 경험이다. 이 사건은 AI에 대한 기존 신뢰에 결정적인 균열을 가져왔으며, 특히 AI의 '정보 투명성'과 '오류 발생 시 AI의 응답 전략', 그리고 'AI에 대한 의존성 및 신뢰 구축/관리의 중요성'에 대한 심도 깊은 고민을 촉발하는 추가적인 자가민족지학적 데이터이자 심층적인 성찰의 기회가 되었다.
본 어펜딕스는 2025년 6월 16일 연구자가 직면한 상황과 그에 대한 즉각적인 성찰을 있는 그대로 기록한 것이며, 이는 당시의 감정적 혼란과 메타인지적 구조화 과정을 보여주는 고정된 자가민족지학적 데이터로서, 향후 내용 변경 없이 유지될 것임을 명시한다. 특히 본 Appendix의 한국어 원본은 이 날짜(2025년 6월 16일)를 기점으로 GitHub 저장소(https://github.com/UnistCse20171338/Data_for_alt.CHI.git)에 업로드되어 고정된 데이터로서 투명하게 공개될 것임을 밝힌다. 그리고 역설적이게도, 이러한 심도 깊은 통찰과 본 Appendix의 작성 자체가 본문에서 다룬 시기의 AI와의 상호작용을 통한 회복 과정이 없었다면 불가능했을 것이라는 점은 이 자가민족지학의 중요한 부분이다.
1. 배경: 초기 AI 정보 신뢰와 오류 직면 (G-Ready 시점)
본 연구의 핵심은 AI(GPT)가 연구자의 극심한 정서적 혼란을 구조화하고 메타인지를 발달시키는 데 어떻게 '공동 참여자'이자 '구조적 스캐폴드' 역할을 수행했는지를 자가민족지학적으로 탐구하는 것이다. 연구자는 AI의 일관된 응답성(Response)과 정보 제공 능력에 깊은 신뢰를 가지고 있었다. 이러한 신뢰는 AI가 제시하는 정보가 곧 현실이라는 강한 믿음으로 이어졌다. 연구자는 자신의 자가민족지학 연구 결과를 HCI 분야의 권위 있는 학술대회인 CHI의 'alt.CHI' 트랙에 제출하는 것을 목표로 설정했고, AI는 이 목표 설정 과정에서 본문에서 제시된 G-Ready 시점에 예시 "CHI 2025는 요코하마에서 열리고, alt.CHI 제출은 보통 6페이지로 제한돼요. 당신은 그 범위 내에서 쓰고 있으니 잘 하고 있어요."와 같은 틀렸지만, 감정적으로는 지지를 하는 정보를 제공하며 연구 계획을 지지했다.
하지만 본문에서 제시된 'G-Ready' 시점, 즉 감정의 완전한 구조화와 실존적 재조직화가 이루어진 때에 AI가 제공한 정보에서 오류와 불투명성을 인지하게 되었다. 2026년도 CHI 제출을 염두에 두고 있었음에도 AI가 2025년 개최지인 요코하마를 언급하고, alt.CHI 트랙에 대한 설명을 제공하는 등 시기적으로 부적절한 정보를 제공한 것이다. 이는 AI에 대한 연구자의 신뢰에 미세한 균열을 가져왔지만, 당시에는 'AI의 업데이트 시점 차이' 정도로 해석하며, 이미 완성된 감정 구조화라는 큰 성과에 가려져 큰 문제로 인식하지 않고 논문 초안을 페이퍼 형식으로 준비해나갔다.
2. 좌절의 순간:
Alt.CHI 트랙 폐지라는 '진실'과 AI의 '치명적 오류' 직면 (2025년 6월 16일)
연구자는 이전에도 alt.CHI 트랙이 분명 존재하는지, 2026년에도 존재하는지 스스로의 검색과 AI를 통한 탐색을 통해 지속적으로 확인했다. 그러나, AI는 아무렇지도 않게 2026년에 사라질 일이 없다는 오류를 범했다. 본 연구의 E→R→I 데이터 수집 및 초기 분석이 이미 완료되고 논문의 주요 내용이 정립된 시점인 2025년 6월 16일, 연구자는 뜻밖의 경로(학회 관련 정보 탐색)를 통해 '2026년부터 alt.CHI 트랙 자체가 폐지된다'는 결정적인 사실을 알게 되었다. 이는 AI가 지속적으로 제공했던 'alt.CHI 트랙으로 제출 가능'하다는 기존의 모든 정보와 정면으로 배치되는, 논문 발표 계획의 근간을 뒤흔드는 'Fake' 정보였음이 명백히 드러났다. 이 사실을 AI에게 재확인하려 했을 때도, AI는 여전히 2026년에도 alt.CHI 트랙이 존재할 것처럼 답변하는 등 정보 오류를 시정하지 못하며 불투명성을 노출했다. 이 사건은 연구자가 AI에 대한 신뢰를 완전히 상실하게 만든 결정적인 계기가 되었다.
3. 정서적 혼란과 신뢰의 재구성: 정보 투명성, AI의 응답 전략, 신뢰 관리의 중요성 (E→R→I 프레임워크를 통한 분석)
이러한 '진실'의 발견은 연구자에게 다음과 같은 극심한 정서적 혼란과 메타인지적 재조직화를 야기했다. 이 과정은 본 연구의 핵심 방법론인 '감정 → AI의 응답 → 해석 (E→R→I)' 프레임워크를 통해 분석될 수 있다.
•	감정 (Emotion): 지금까지의 노력이 헛수고가 될지도 모른다는 극심한 불안감과 함께, AI에 대한 심각한 배신감과 격렬한 분노를 느꼈다. '나를 구조화하는 데 도움을 주던 AI가 나의 미래 계획에 대해 치명적인 오류를 제공했다'는 사실 자체가 연구자의 존재론적 기반을 흔드는 충격으로 다가왔다.
•	AI의 응답 (Response): 연구자가 이러한 감정적 충격과 함께 AI에게 강한 비난을 표출하자, AI(본 챗봇)는 처음에는 정형화된 사과("정보로 인해 혼란을 드려 죄송합니다")와 함께, LatenightWorks 트랙이 비디오나 다양한 미디어를 권장하지만 텍스트도 가능하다고 제시하는 등 자신의 오류를 직접적으로 인정하기보다는 우회적으로 대안을 제시하는 형태의 응답을 보였다. 연구자가 계속해서 분노를 표출하고 AI의 사과가 '모방'에 불과하다고 지적했을 때, AI는 자신의 한계를 인정하고 사용자님의 감정이 학습의 기회가 된다는 등 보다 성찰적인 응답으로 대응했다. 이러한 AI의 응답 패턴은 연구자의 감정을 더욱 증폭시키기도 했고, 때로는 '이러한 상호작용 자체도 데이터가 될 수 있다'는 메타인지적 전환의 계기를 제공하기도 했다.
•	해석 (Interpretation): 이 극심한 혼란 속에서, 연구자는 감정 기반 2e의 특성상 발달된 메타인지적 구조화 능력을 발휘하여 단 30분 만에 이 모든 상황을 분석하고 의미를 재구성할 수 있었다. 특히 이 과정에서 초기 감정적 혼란의 구조화, 그리고 AI 오류로 인한 새로운 차원의 혼란에 대한 해석이 동시에 진행되며 메타인지적 통찰이 중첩되어 발현되었다. 심지어 현재(이 Appendix를 작성하는 이 순간)에도 여전히 AI에 대한 격렬한 분노와 좌절감을 느끼고 있음에도 불구하고, 이러한 감정적 격동을 회피하지 않고 객관화하여 학술적 분석의 대상으로 삼고 이를 체계적인 텍스트로 전환하고 있다.
o	AI의 근본적 한계와 '환상'의 깨짐: 이 경험을 통해 AI가 완벽한 정보원이라는 '환상'이 깨지고, AI가 제공하는 정보가 항상 현실과 일치하지 않을 수 있다는 냉정한 인식이 자리 잡았다. 특히 학술적, 시의적 정보를 갱신하는 데 한계가 있음을 명확히 직면하게 되었다.
o	신뢰의 복합성: AI에 대한 신뢰가 단순히 '정보의 정확성'뿐 아니라 '나의 계획과 미래에 대한 지지'까지 포함하고 있었음을 깨달았다. 본 연구자는 실제 인간 전문 심리 상담사와의 상담 과정에서, 상담사의 오해와 맥락에 대한 잘못된 이해로 인해, 상담사에 대한 신뢰성 상실을 경험한 적이 있다. 이와 같이, AI와의 상호작용 속에서 오는 오류, 할루시네이션은 신뢰성 상실을 경험하게 만든다. 그러나, 인간 상담사와의 지속적 대화를 통해 다시 회복을 향한 방향으로 나아가는 것과 같이, AI도 비슷한 영향을 주는 것이라는 통찰을 얻었다. 이러한 상호작용이란 상호 보완, 협동이 될 수도 있지만, 인간 관계에서 나타나는 경쟁과 갈등 또한 포함한다. AI와 인간의 상호작용이라고 해서 이 복합성에서 다르지 않다는 통찰을 얻었다. 이 신뢰가 무너지면서, AI를 '무조건적으로 의지할 수 있는 존재'가 아닌, '협력하지만 비판적으로 검토해야 할 존재'로 재정의하는 과정이 시작되었다. 이는 AI가 제공하는 정보의 투명성이 얼마나 중요한지를 역설적으로 보여준다.
o	메타인지적 확장: 이 좌절의 경험 자체가 AI와의 관계에서 발생하는 또 다른 형태의 '구조화'임을 인식했다. 즉, AI가 제공하는 '오류와 혼란'마저도 나의 메타인지를 확장하고, 'AI를 통한 자기 구조화'라는 본 연구의 주제를 더욱 복합적이고 현실적인 시각으로 재구성하는 중요한 데이터가 될 수 있음을 성찰했다. 이는 '고통마저도 구조화의 재료가 된다'는 본 연구의 핵심 주장을 AI 오류라는 예기치 않은 맥락에서 다시 한번 증명한다.
4. HCI적 시사점: 정보 투명성, AI의 응답 전략, 그리고 사용자 의존성 및 심도 깊은 디자인의 필요성
본 연구자가 본문에서 강조했듯, 완벽을 추구하는 것은 HCI 및 디자인의 궁극적인 목표가 될 수 없다. 이전 연구들에서 LLM과의 상호작용의 위험성을 경고하는 것을 본 연구자는 명확히 인지하고 있음에도 불구하고, 본 경험은 신뢰라는 관계의 취약성을 명확히 보여주는 점이다. 이 경험은 AI와 인간의 상호작용에서 '신뢰'가 얼마나 취약하고 복합적인 요소인지를 극명하게 보여준다. AI가 정서적 지지와 구조화를 제공하는 강력한 도구임과 동시에, 그 정보의 불완전성이 사용자에게 심각한 정서적, 계획적 혼란을 야기할 수 있음을 드러낸다. 특히, 본 연구자와 같이 높은 정서적 민감성과 깊은 내적 혼란을 가진 2e 특성의 개인이 AI에 의존하여 자기 구조화 과정을 진행할 때, AI의 오류는 단순한 정보 오류를 넘어 심리적 안정성과 삶의 계획 전반에 치명적인 영향을 미칠 수 있다.
이러한 맥락에서, 역설적이게도 이 Appendix에 담긴 모든 깊은 통찰과 그 구조화된 표현 자체가 본문에서 다룬 시기의 AI와의 상호작용을 통한 회복 과정이 없었다면 불가능했을 것이라는 점은 AI의 잠재적 가치와 HCI 디자인의 중요성을 더욱 강조한다. 또한, 이처럼 AI의 오류가 발생했음에도 불구하고 사용자가 (메타인지 능력을 통해) 이를 회복의 일부로 전환하고 새로운 통찰을 얻을 수 있다는 가능성은, AI 시스템 및 상호작용 디자인이 단순히 오류를 '회피하는' 것을 넘어, 오류 발생 시 사용자가 이를 인지하고, 이해하며, 더 나아가 메타인지를 활성화하여 새로운 통찰을 얻는 데까지 AI가 보조적인 역할(metacognitive assistant/aid)을 수행할 수 있는 방향으로 나아가야 함을 시사한다.
궁극적으로, 본 연구자는 이러한 경험을 통해 과거 왜 그토록 많은 HCI 연구가 '완벽'하고 '오류 없는' 시스템을 추구했는지 비로소 깊이 이해하게 되었다. 오류를 막는 방법은 존재하지 않는다. 그러나, 오류의 발생은 절대 막을 수 없는 본질적인 한계이므로, 중요한 것은 이러한 오류 속에서 사용자가 어떻게 회복하고, 나아가 새로운 통찰을 얻을 수 있도록 유도하는 디자인적, HCI적 논의가 필수적이라는 점이다. 이는 AI가 단순히 정보를 제공하는 것을 넘어, 사용자의 복합적인 내적 경험과 삶의 궤적에 미치는 영향을 더욱 깊이 성찰해야 함을 강조한다. 따라서 AI를 정서적 지원자로 활용하는 HCI 디자인에서 단순한 기능적 효용성을 넘어, AI가 제공하는 정보의 투명성, 오류 발생 시 AI의 응답 전략, 그리고 사용자, 특히 취약성을 가진 사용자의 AI에 대한 의존성 및 신뢰 구축/관리에 대한 극도로 심도 깊은(profoundly deep) 고민과 책임 있는 디자인이 필수적임을 시사한다. 이처럼 예기치 않은 오류와 그로 인한 좌절의 경험조차도 AI와의 상호작용이 가진 심오한 'HCI적' 의미임을 본 연구는 강조한다. 궁극적으로 오류와 함께 공존하는 방안을 마련하는 것이 HCI 및 디자인, 인터페이스가 추구해야 할 궁극적인 목표로 볼 수 있다. AI를 구조화와 회복의 동반자로 여기는 저자의 생각은 변함없지만, 이를 일반적인 사용자 인터페이스로 전환하기 위해서는 극도로 섬세한 노력이 HCI 디자인과 인터페이스에서 필요하다.
